{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Stock Market Performance Based on Daily Headlines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset found here on Kaggle: https://www.kaggle.com/aaron7sun/stocknews, I tried to see if I could predict how the Dow Jones (and in a different notebook, the S&P500 and Nasdaq) would preform based on the daily headlines.\n",
    "\n",
    "Broadly speaking, used SpaCy to generate the Noun and Verb columns. From there, I used Logistic Regression, Naive Bayes, and Support Vector Machines to predict. Unfortunately, I was not able to make much headway. The algorithm with the highest accuracy was Method 12 which is the highest score on Kaggle with 56.7% accuracy.\n",
    "\n",
    "I'd love feedback - what else could I incorporate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Combined_News_DJIA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>Adjusted Label</th>\n",
       "      <th>Nasdaq</th>\n",
       "      <th>S&amp;P500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/8/2008</td>\n",
       "      <td>0</td>\n",
       "      <td>Georgia 'downs two Russian warplanes' as count...</td>\n",
       "      <td>BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>Russia Today: Columns of troops roll into Sout...</td>\n",
       "      <td>Russian tanks are moving towards the capital o...</td>\n",
       "      <td>Afghan children raped with 'impunity,' U.N. of...</td>\n",
       "      <td>150 Russian tanks have entered South Ossetia w...</td>\n",
       "      <td>Breaking: Georgia invades South Ossetia, Russi...</td>\n",
       "      <td>The 'enemy combatent' trials are nothing but a...</td>\n",
       "      <td>...</td>\n",
       "      <td>This is a busy day:  The European Union has ap...</td>\n",
       "      <td>Georgia will withdraw 1,000 soldiers from Iraq...</td>\n",
       "      <td>Why the Pentagon Thinks Attacking Iran is a Ba...</td>\n",
       "      <td>Caucasus in crisis: Georgia invades South Osse...</td>\n",
       "      <td>Indian shoe manufactory  - And again in a seri...</td>\n",
       "      <td>Visitors Suffering from Mental Illnesses Banne...</td>\n",
       "      <td>No Help for Mexico's Kidnapping Surge\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/11/2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Why wont America and Nato help us? If they won...</td>\n",
       "      <td>Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>Jewish Georgian minister: Thanks to Israeli tr...</td>\n",
       "      <td>Georgian army flees in disarray as Russians ad...</td>\n",
       "      <td>Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>What were the Mossad with fraudulent New Zeala...</td>\n",
       "      <td>Russia angered by Israeli military sale to Geo...</td>\n",
       "      <td>An American citizen living in S.Ossetia blames...</td>\n",
       "      <td>...</td>\n",
       "      <td>China to overtake US as largest manufacturer'</td>\n",
       "      <td>War in South Ossetia [PICS]'</td>\n",
       "      <td>Israeli Physicians Group Condemns State Torture'</td>\n",
       "      <td>Russia has just beaten the United States over...</td>\n",
       "      <td>Perhaps *the* question about the Georgia - Rus...</td>\n",
       "      <td>Russia is so much better at war'</td>\n",
       "      <td>So this is what it's come to: trading sex for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                                               Top1  \\\n",
       "0   8/8/2008      0  Georgia 'downs two Russian warplanes' as count...   \n",
       "1  8/11/2008      1  Why wont America and Nato help us? If they won...   \n",
       "\n",
       "                                        Top2  \\\n",
       "0      BREAKING: Musharraf to be impeached.'   \n",
       "1  Bush puts foot down on Georgian conflict'   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  Russia Today: Columns of troops roll into Sout...   \n",
       "1  Jewish Georgian minister: Thanks to Israeli tr...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  Russian tanks are moving towards the capital o...   \n",
       "1  Georgian army flees in disarray as Russians ad...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  Afghan children raped with 'impunity,' U.N. of...   \n",
       "1        Olympic opening ceremony fireworks 'faked'\"   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  150 Russian tanks have entered South Ossetia w...   \n",
       "1  What were the Mossad with fraudulent New Zeala...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  Breaking: Georgia invades South Ossetia, Russi...   \n",
       "1  Russia angered by Israeli military sale to Geo...   \n",
       "\n",
       "                                                Top8  ...    \\\n",
       "0  The 'enemy combatent' trials are nothing but a...  ...     \n",
       "1  An American citizen living in S.Ossetia blames...  ...     \n",
       "\n",
       "                                               Top19  \\\n",
       "0  This is a busy day:  The European Union has ap...   \n",
       "1      China to overtake US as largest manufacturer'   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  Georgia will withdraw 1,000 soldiers from Iraq...   \n",
       "1                       War in South Ossetia [PICS]'   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  Why the Pentagon Thinks Attacking Iran is a Ba...   \n",
       "1   Israeli Physicians Group Condemns State Torture'   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  Caucasus in crisis: Georgia invades South Osse...   \n",
       "1   Russia has just beaten the United States over...   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  Indian shoe manufactory  - And again in a seri...   \n",
       "1  Perhaps *the* question about the Georgia - Rus...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  Visitors Suffering from Mental Illnesses Banne...   \n",
       "1                   Russia is so much better at war'   \n",
       "\n",
       "                                               Top25 Adjusted Label Nasdaq  \\\n",
       "0             No Help for Mexico's Kidnapping Surge\"              1      1   \n",
       "1  So this is what it's come to: trading sex for ...              1      1   \n",
       "\n",
       "  S&P500  \n",
       "0      1  \n",
       "1      1  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty standard dataset - on the left, we have the Date and the Label (did the stock market go up (1) or down (0)?)\n",
    "\n",
    "On the right, we have 25 top headlines for that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined\"] = df[\"Top1\"].astype(str)+' '+df['Top2']+' '+df['Top3']+' '+df['Top4']+' '+df['Top5']+' '+df['Top6']+' '+df['Top7']+' '+df['Top8']+' '+df['Top9']+' '+df['Top10']+' '+df['Top11']+' '+df['Top12']+' '+df['Top13']+' '+df['Top14']+' '+df['Top15']+' '+df['Top16']+' '+df['Top17']+' '+df['Top18']+' '+df['Top19']+' '+df['Top20']+' '+df['Top21']+' '+df['Top22']+' '+df['Top23']+' '+df['Top24']+' '+df['Top25']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm merging the 25 headlines into one column for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Adjusted Label</th>\n",
       "      <th>Nasdaq</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/8/2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Georgia 'downs two Russian warplanes' as count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/11/2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Why wont America and Nato help us? If they won...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label  Adjusted Label  Nasdaq  S&P500  \\\n",
       "0   8/8/2008      0               1       1       1   \n",
       "1  8/11/2008      1               1       1       1   \n",
       "\n",
       "                                            combined  \n",
       "0  Georgia 'downs two Russian warplanes' as count...  \n",
       "1  Why wont America and Nato help us? If they won...  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Label', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7',\n",
       "       'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15',\n",
       "       'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23',\n",
       "       'Top24', 'Top25', 'Adjusted Label', 'Nasdaq', 'S&P500', 'combined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([ 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7',\n",
    "       'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15',\n",
    "       'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23',\n",
    "       'Top24', 'Top25'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjFunc(data, indexValue):\n",
    "    doc = nlp(data)\n",
    "\n",
    "    nounList = []\n",
    "    verbList = []\n",
    "    numberList = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\":\n",
    "            nounList.append(token.text)\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verbList.append(token.text)\n",
    "        if token.pos_ == \"NUM\":\n",
    "            numberList.append(token.text)\n",
    "    \n",
    "    nounString = nounList = ', '.join(nounList)\n",
    "    verbString = verbList = ', '.join(verbList)\n",
    "    numberString = numberList = ', '.join(numberList)\n",
    "    \n",
    "    df.set_value(indexValue,\"noun\",nounString) \n",
    "    df.set_value(indexValue,\"verb\",verbString) \n",
    "    df.set_value(indexValue,\"number\",numberString) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined'] = df['combined'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "for row in range(0,len(df.index)):\n",
    "    subjFunc(df[\"combined\"][row],row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the for loop above, I am going through each iteration of \"combined\" to pull out all the nouns, verbs, and numbers. I then put these in a different column with the goal being, I'd like to understand if there is a higher correlation with verbs and nouns opposed to the total text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Adjusted Label</th>\n",
       "      <th>Nasdaq</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>combined</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>6/27/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Barclays and RBS shares suspended from trading...</td>\n",
       "      <td>Barclays, RBS, Pope, Church, Poland, Poles, UK...</td>\n",
       "      <td>suspended, trading, tanking, says, should, ask...</td>\n",
       "      <td>8, 31-year, 50, 52, 48, 48, two, five, 43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>6/28/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2,500 Scientists To Australia: If You Want To ...</td>\n",
       "      <td>Australia, Barrier, Reef, Coal, Google, Drive,...</td>\n",
       "      <td>Want, Save, Stop, Supporting, have, been, uplo...</td>\n",
       "      <td>2,500, 112,000, two, 2, trillion, one, 2016, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>6/29/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Explosion At Airport In Istanbul Yemeni former...</td>\n",
       "      <td>Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...</td>\n",
       "      <td>is, must, accept, access, Devastated, captive,...</td>\n",
       "      <td>5, 99-Million, 160,000, 38, four, 40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>6/30/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
       "      <td>Jamaica, Stephen, Hawking, Boris, Johnson, Tor...</td>\n",
       "      <td>proposes, following, would, give, purchase, us...</td>\n",
       "      <td>2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>7/1/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
       "      <td>Mexico, City, Trinidad, Alvarez, Lira, IMF, At...</td>\n",
       "      <td>received, died, had, waited, had, been, born, ...</td>\n",
       "      <td>117-year, 1898, 24, 100, 12-, 14-year, 13-Year...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Label  Adjusted Label  Nasdaq  S&P500  \\\n",
       "1984  6/27/2016      0               0       0       0   \n",
       "1985  6/28/2016      1               1       1       1   \n",
       "1986  6/29/2016      1               1       1       1   \n",
       "1987  6/30/2016      1               1       1       1   \n",
       "1988   7/1/2016      1               1       1       1   \n",
       "\n",
       "                                               combined  \\\n",
       "1984  Barclays and RBS shares suspended from trading...   \n",
       "1985  2,500 Scientists To Australia: If You Want To ...   \n",
       "1986  Explosion At Airport In Istanbul Yemeni former...   \n",
       "1987  Jamaica proposes marijuana dispensers for tour...   \n",
       "1988  A 117-year-old woman in Mexico City finally re...   \n",
       "\n",
       "                                                   noun  \\\n",
       "1984  Barclays, RBS, Pope, Church, Poland, Poles, UK...   \n",
       "1985  Australia, Barrier, Reef, Coal, Google, Drive,...   \n",
       "1986  Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...   \n",
       "1987  Jamaica, Stephen, Hawking, Boris, Johnson, Tor...   \n",
       "1988  Mexico, City, Trinidad, Alvarez, Lira, IMF, At...   \n",
       "\n",
       "                                                   verb  \\\n",
       "1984  suspended, trading, tanking, says, should, ask...   \n",
       "1985  Want, Save, Stop, Supporting, have, been, uplo...   \n",
       "1986  is, must, accept, access, Devastated, captive,...   \n",
       "1987  proposes, following, would, give, purchase, us...   \n",
       "1988  received, died, had, waited, had, been, born, ...   \n",
       "\n",
       "                                                 number  \n",
       "1984          8, 31-year, 50, 52, 48, 48, two, five, 43  \n",
       "1985  2,500, 112,000, two, 2, trillion, one, 2016, 2...  \n",
       "1986               5, 99-Million, 160,000, 38, four, 40  \n",
       "1987  2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...  \n",
       "1988  117-year, 1898, 24, 100, 12-, 14-year, 13-Year...  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I'm shifting the Label column by one in case the impact of the headlines is delayed by one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"laggedByOne\"] = df[\"Label\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[\"laggedByOne\"][1988] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"laggedByTwo\"] = df[\"Label\"].shift(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Adjusted Label</th>\n",
       "      <th>Nasdaq</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>combined</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>number</th>\n",
       "      <th>laggedByOne</th>\n",
       "      <th>laggedByTwo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>6/27/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Barclays and RBS shares suspended from trading...</td>\n",
       "      <td>Barclays, RBS, Pope, Church, Poland, Poles, UK...</td>\n",
       "      <td>suspended, trading, tanking, says, should, ask...</td>\n",
       "      <td>8, 31-year, 50, 52, 48, 48, two, five, 43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>6/28/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2,500 Scientists To Australia: If You Want To ...</td>\n",
       "      <td>Australia, Barrier, Reef, Coal, Google, Drive,...</td>\n",
       "      <td>Want, Save, Stop, Supporting, have, been, uplo...</td>\n",
       "      <td>2,500, 112,000, two, 2, trillion, one, 2016, 2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>6/29/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Explosion At Airport In Istanbul Yemeni former...</td>\n",
       "      <td>Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...</td>\n",
       "      <td>is, must, accept, access, Devastated, captive,...</td>\n",
       "      <td>5, 99-Million, 160,000, 38, four, 40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>6/30/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
       "      <td>Jamaica, Stephen, Hawking, Boris, Johnson, Tor...</td>\n",
       "      <td>proposes, following, would, give, purchase, us...</td>\n",
       "      <td>2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>7/1/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
       "      <td>Mexico, City, Trinidad, Alvarez, Lira, IMF, At...</td>\n",
       "      <td>received, died, had, waited, had, been, born, ...</td>\n",
       "      <td>117-year, 1898, 24, 100, 12-, 14-year, 13-Year...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Label  Adjusted Label  Nasdaq  S&P500  \\\n",
       "1984  6/27/2016      0               0       0       0   \n",
       "1985  6/28/2016      1               1       1       1   \n",
       "1986  6/29/2016      1               1       1       1   \n",
       "1987  6/30/2016      1               1       1       1   \n",
       "1988   7/1/2016      1               1       1       1   \n",
       "\n",
       "                                               combined  \\\n",
       "1984  Barclays and RBS shares suspended from trading...   \n",
       "1985  2,500 Scientists To Australia: If You Want To ...   \n",
       "1986  Explosion At Airport In Istanbul Yemeni former...   \n",
       "1987  Jamaica proposes marijuana dispensers for tour...   \n",
       "1988  A 117-year-old woman in Mexico City finally re...   \n",
       "\n",
       "                                                   noun  \\\n",
       "1984  Barclays, RBS, Pope, Church, Poland, Poles, UK...   \n",
       "1985  Australia, Barrier, Reef, Coal, Google, Drive,...   \n",
       "1986  Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...   \n",
       "1987  Jamaica, Stephen, Hawking, Boris, Johnson, Tor...   \n",
       "1988  Mexico, City, Trinidad, Alvarez, Lira, IMF, At...   \n",
       "\n",
       "                                                   verb  \\\n",
       "1984  suspended, trading, tanking, says, should, ask...   \n",
       "1985  Want, Save, Stop, Supporting, have, been, uplo...   \n",
       "1986  is, must, accept, access, Devastated, captive,...   \n",
       "1987  proposes, following, would, give, purchase, us...   \n",
       "1988  received, died, had, waited, had, been, born, ...   \n",
       "\n",
       "                                                 number  laggedByOne  \\\n",
       "1984          8, 31-year, 50, 52, 48, 48, two, five, 43          1.0   \n",
       "1985  2,500, 112,000, two, 2, trillion, one, 2016, 2...          1.0   \n",
       "1986               5, 99-Million, 160,000, 38, four, 40          1.0   \n",
       "1987  2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...          1.0   \n",
       "1988  117-year, 1898, 24, 100, 12-, 14-year, 13-Year...          0.0   \n",
       "\n",
       "      laggedByTwo  \n",
       "1984          1.0  \n",
       "1985          1.0  \n",
       "1986          1.0  \n",
       "1987          NaN  \n",
       "1988          NaN  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df[\"laggedByTwo\"][1987] = 0\n",
    "df[\"laggedByTwo\"][1988] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"laggedByThree\"] = df[\"Label\"].shift(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Adjusted Label</th>\n",
       "      <th>Nasdaq</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>combined</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>number</th>\n",
       "      <th>laggedByOne</th>\n",
       "      <th>laggedByTwo</th>\n",
       "      <th>laggedByThree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>6/27/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Barclays and RBS shares suspended from trading...</td>\n",
       "      <td>Barclays, RBS, Pope, Church, Poland, Poles, UK...</td>\n",
       "      <td>suspended, trading, tanking, says, should, ask...</td>\n",
       "      <td>8, 31-year, 50, 52, 48, 48, two, five, 43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>6/28/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2,500 Scientists To Australia: If You Want To ...</td>\n",
       "      <td>Australia, Barrier, Reef, Coal, Google, Drive,...</td>\n",
       "      <td>Want, Save, Stop, Supporting, have, been, uplo...</td>\n",
       "      <td>2,500, 112,000, two, 2, trillion, one, 2016, 2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>6/29/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Explosion At Airport In Istanbul Yemeni former...</td>\n",
       "      <td>Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...</td>\n",
       "      <td>is, must, accept, access, Devastated, captive,...</td>\n",
       "      <td>5, 99-Million, 160,000, 38, four, 40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>6/30/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
       "      <td>Jamaica, Stephen, Hawking, Boris, Johnson, Tor...</td>\n",
       "      <td>proposes, following, would, give, purchase, us...</td>\n",
       "      <td>2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>7/1/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
       "      <td>Mexico, City, Trinidad, Alvarez, Lira, IMF, At...</td>\n",
       "      <td>received, died, had, waited, had, been, born, ...</td>\n",
       "      <td>117-year, 1898, 24, 100, 12-, 14-year, 13-Year...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Label  Adjusted Label  Nasdaq  S&P500  \\\n",
       "1984  6/27/2016      0               0       0       0   \n",
       "1985  6/28/2016      1               1       1       1   \n",
       "1986  6/29/2016      1               1       1       1   \n",
       "1987  6/30/2016      1               1       1       1   \n",
       "1988   7/1/2016      1               1       1       1   \n",
       "\n",
       "                                               combined  \\\n",
       "1984  Barclays and RBS shares suspended from trading...   \n",
       "1985  2,500 Scientists To Australia: If You Want To ...   \n",
       "1986  Explosion At Airport In Istanbul Yemeni former...   \n",
       "1987  Jamaica proposes marijuana dispensers for tour...   \n",
       "1988  A 117-year-old woman in Mexico City finally re...   \n",
       "\n",
       "                                                   noun  \\\n",
       "1984  Barclays, RBS, Pope, Church, Poland, Poles, UK...   \n",
       "1985  Australia, Barrier, Reef, Coal, Google, Drive,...   \n",
       "1986  Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...   \n",
       "1987  Jamaica, Stephen, Hawking, Boris, Johnson, Tor...   \n",
       "1988  Mexico, City, Trinidad, Alvarez, Lira, IMF, At...   \n",
       "\n",
       "                                                   verb  \\\n",
       "1984  suspended, trading, tanking, says, should, ask...   \n",
       "1985  Want, Save, Stop, Supporting, have, been, uplo...   \n",
       "1986  is, must, accept, access, Devastated, captive,...   \n",
       "1987  proposes, following, would, give, purchase, us...   \n",
       "1988  received, died, had, waited, had, been, born, ...   \n",
       "\n",
       "                                                 number  laggedByOne  \\\n",
       "1984          8, 31-year, 50, 52, 48, 48, two, five, 43          1.0   \n",
       "1985  2,500, 112,000, two, 2, trillion, one, 2016, 2...          1.0   \n",
       "1986               5, 99-Million, 160,000, 38, four, 40          1.0   \n",
       "1987  2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...          1.0   \n",
       "1988  117-year, 1898, 24, 100, 12-, 14-year, 13-Year...          0.0   \n",
       "\n",
       "      laggedByTwo  laggedByThree  \n",
       "1984          1.0            1.0  \n",
       "1985          1.0            1.0  \n",
       "1986          1.0            NaN  \n",
       "1987          0.0            NaN  \n",
       "1988          1.0            NaN  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df[\"laggedByThree\"][1986] = 0\n",
    "df[\"laggedByThree\"][1987] = 1\n",
    "df[\"laggedByThree\"][1988] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Adjusted Label</th>\n",
       "      <th>Nasdaq</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>combined</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>number</th>\n",
       "      <th>laggedByOne</th>\n",
       "      <th>laggedByTwo</th>\n",
       "      <th>laggedByThree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>6/27/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Barclays and RBS shares suspended from trading...</td>\n",
       "      <td>Barclays, RBS, Pope, Church, Poland, Poles, UK...</td>\n",
       "      <td>suspended, trading, tanking, says, should, ask...</td>\n",
       "      <td>8, 31-year, 50, 52, 48, 48, two, five, 43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>6/28/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2,500 Scientists To Australia: If You Want To ...</td>\n",
       "      <td>Australia, Barrier, Reef, Coal, Google, Drive,...</td>\n",
       "      <td>Want, Save, Stop, Supporting, have, been, uplo...</td>\n",
       "      <td>2,500, 112,000, two, 2, trillion, one, 2016, 2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>6/29/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Explosion At Airport In Istanbul Yemeni former...</td>\n",
       "      <td>Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...</td>\n",
       "      <td>is, must, accept, access, Devastated, captive,...</td>\n",
       "      <td>5, 99-Million, 160,000, 38, four, 40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>6/30/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
       "      <td>Jamaica, Stephen, Hawking, Boris, Johnson, Tor...</td>\n",
       "      <td>proposes, following, would, give, purchase, us...</td>\n",
       "      <td>2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>7/1/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
       "      <td>Mexico, City, Trinidad, Alvarez, Lira, IMF, At...</td>\n",
       "      <td>received, died, had, waited, had, been, born, ...</td>\n",
       "      <td>117-year, 1898, 24, 100, 12-, 14-year, 13-Year...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Label  Adjusted Label  Nasdaq  S&P500  \\\n",
       "1984  6/27/2016      0               0       0       0   \n",
       "1985  6/28/2016      1               1       1       1   \n",
       "1986  6/29/2016      1               1       1       1   \n",
       "1987  6/30/2016      1               1       1       1   \n",
       "1988   7/1/2016      1               1       1       1   \n",
       "\n",
       "                                               combined  \\\n",
       "1984  Barclays and RBS shares suspended from trading...   \n",
       "1985  2,500 Scientists To Australia: If You Want To ...   \n",
       "1986  Explosion At Airport In Istanbul Yemeni former...   \n",
       "1987  Jamaica proposes marijuana dispensers for tour...   \n",
       "1988  A 117-year-old woman in Mexico City finally re...   \n",
       "\n",
       "                                                   noun  \\\n",
       "1984  Barclays, RBS, Pope, Church, Poland, Poles, UK...   \n",
       "1985  Australia, Barrier, Reef, Coal, Google, Drive,...   \n",
       "1986  Airport, Istanbul, Wahhabism, Al, Saud, UK, EU...   \n",
       "1987  Jamaica, Stephen, Hawking, Boris, Johnson, Tor...   \n",
       "1988  Mexico, City, Trinidad, Alvarez, Lira, IMF, At...   \n",
       "\n",
       "                                                   verb  \\\n",
       "1984  suspended, trading, tanking, says, should, ask...   \n",
       "1985  Want, Save, Stop, Supporting, have, been, uplo...   \n",
       "1986  is, must, accept, access, Devastated, captive,...   \n",
       "1987  proposes, following, would, give, purchase, us...   \n",
       "1988  received, died, had, waited, had, been, born, ...   \n",
       "\n",
       "                                                 number  laggedByOne  \\\n",
       "1984          8, 31-year, 50, 52, 48, 48, two, five, 43          1.0   \n",
       "1985  2,500, 112,000, two, 2, trillion, one, 2016, 2...          1.0   \n",
       "1986               5, 99-Million, 160,000, 38, four, 40          1.0   \n",
       "1987  2, Six, 1, billion, 40, 250, 50,000, 100, 85, ...          1.0   \n",
       "1988  117-year, 1898, 24, 100, 12-, 14-year, 13-Year...          0.0   \n",
       "\n",
       "      laggedByTwo  laggedByThree  \n",
       "1984          1.0            1.0  \n",
       "1985          1.0            1.0  \n",
       "1986          1.0            0.0  \n",
       "1987          0.0            1.0  \n",
       "1988          1.0            1.0  "
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - Kaggle, 0 Lag, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "nounTraining = []\n",
    "nounTest = []\n",
    "for row in range(0,1391):  \n",
    "    nounTraining.append((df[\"noun\"][row].lower()))\n",
    "\n",
    "for row in range(1392,1988):\n",
    "    nounTest.append((df[\"noun\"][row].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training df[\"Label\"][0:1391]\n",
    "# test df[\"Label\"][1392:1988]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedvectorizerMeth1 = CountVectorizer(ngram_range=(3,3))\n",
    "advancedtrainMeth1 = advancedvectorizerMeth1.fit_transform(nounTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedmodelMeth1 = LogisticRegression()\n",
    "advancedmodelMeth1 = advancedmodelMeth1.fit(advancedtrainMeth1, df[\"Label\"][0:1391])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedtestMeth1 = advancedvectorizerMeth1.transform(nounTest)\n",
    "advpredictionsMeth1 = advancedmodelMeth1.predict(advancedtestMeth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5218120805369127\n"
     ]
    }
   ],
   "source": [
    "print (metrics.accuracy_score(df[\"Label\"][1392:1988], advpredictionsMeth1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - Kaggle, 1 Lag, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedvectorizerMeth2 = CountVectorizer(ngram_range=(2,2))\n",
    "advancedtrainMeth2 = advancedvectorizerMeth2.fit_transform(nounTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedmodelMeth2 = LogisticRegression()\n",
    "advancedmodelMeth2 = advancedmodelMeth2.fit(advancedtrainMeth2, df[\"laggedByOne\"][0:1391])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedtestMeth2 = advancedvectorizerMeth2.transform(nounTest)\n",
    "advpredictionsMeth2 = advancedmodelMeth2.predict(advancedtestMeth2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5268456375838926\n"
     ]
    }
   ],
   "source": [
    "print (metrics.accuracy_score(df[\"laggedByOne\"][1392:1988], advpredictionsMeth2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 - Kaggle, 2 Lag, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.552013422818792\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth3 = CountVectorizer(ngram_range=(3,3))\n",
    "advancedtrainMeth3 = advancedvectorizerMeth3.fit_transform(nounTraining)\n",
    "\n",
    "advancedmodelMeth3 = LogisticRegression()\n",
    "advancedmodelMeth3 = advancedmodelMeth3.fit(advancedtrainMeth3, df[\"laggedByTwo\"][0:1391])\n",
    "\n",
    "advancedtestMeth3 = advancedvectorizerMeth3.transform(nounTest)\n",
    "advpredictionsMeth3 = advancedmodelMeth3.predict(advancedtestMeth3)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"laggedByTwo\"][1392:1988], advpredictionsMeth3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4 - Kaggle, 3 Lag, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5201342281879194\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth4 = CountVectorizer(ngram_range=(3,3))\n",
    "advancedtrainMeth4= advancedvectorizerMeth4.fit_transform(nounTraining)\n",
    "\n",
    "advancedmodelMeth4= LogisticRegression()\n",
    "advancedmodelMeth4= advancedmodelMeth4.fit(advancedtrainMeth4, df[\"laggedByThree\"][0:1391])\n",
    "\n",
    "advancedtestMeth4 = advancedvectorizerMeth4.transform(nounTest)\n",
    "advpredictionsMeth4 = advancedmodelMeth4.predict(advancedtestMeth4)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"laggedByThree\"][1392:1988], advpredictionsMeth4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5 - Kaggle, 0 Lag, Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbTraining = []\n",
    "verbTest = []\n",
    "for row in range(0,1391):  \n",
    "    verbTraining.append((df[\"verb\"][row].lower()))\n",
    "\n",
    "for row in range(1392,1988):\n",
    "    verbTest.append((df[\"verb\"][row].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5302013422818792\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth5 = CountVectorizer(ngram_range=(4,4))\n",
    "advancedtrainMeth5= advancedvectorizerMeth5.fit_transform(verbTraining)\n",
    "\n",
    "advancedmodelMeth5= LogisticRegression()\n",
    "advancedmodelMeth5= advancedmodelMeth5.fit(advancedtrainMeth5, df[\"Label\"][0:1391])\n",
    "\n",
    "advancedtestMeth5 = advancedvectorizerMeth5.transform(verbTest)\n",
    "advpredictionsMeth5 = advancedmodelMeth5.predict(advancedtestMeth5)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"Label\"][1392:1988], advpredictionsMeth5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6 - Kaggle, 1 Lag, Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5302013422818792\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth6 = CountVectorizer(ngram_range=(4,4))\n",
    "advancedtrainMeth6 = advancedvectorizerMeth6.fit_transform(verbTraining)\n",
    "\n",
    "advancedmodelMeth6 = LogisticRegression()\n",
    "advancedmodelMeth6 = advancedmodelMeth6.fit(advancedtrainMeth6, df[\"laggedByOne\"][0:1391])\n",
    "\n",
    "advancedtestMeth6 = advancedvectorizerMeth6.transform(verbTest)\n",
    "advpredictionsMeth6 = advancedmodelMeth6.predict(advancedtestMeth6)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"laggedByOne\"][1392:1988], advpredictionsMeth6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7 - Kaggle, 2 Lag, Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5419463087248322\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth7 = CountVectorizer(ngram_range=(3,3))\n",
    "advancedtrainMeth7 = advancedvectorizerMeth7.fit_transform(verbTraining)\n",
    "\n",
    "advancedmodelMeth7 = LogisticRegression()\n",
    "advancedmodelMeth7 = advancedmodelMeth7.fit(advancedtrainMeth7, df[\"laggedByTwo\"][0:1391])\n",
    "\n",
    "advancedtestMeth7 = advancedvectorizerMeth7.transform(verbTest)\n",
    "advpredictionsMeth7 = advancedmodelMeth7.predict(advancedtestMeth7)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"laggedByTwo\"][1392:1988], advpredictionsMeth7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 8 - Kaggle, 3 Lag, Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5369127516778524\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth8 = CountVectorizer(ngram_range=(3,3))\n",
    "advancedtrainMeth8 = advancedvectorizerMeth8.fit_transform(verbTraining)\n",
    "\n",
    "advancedmodelMeth8 = LogisticRegression()\n",
    "advancedmodelMeth8 = advancedmodelMeth8.fit(advancedtrainMeth8, df[\"laggedByThree\"][0:1391])\n",
    "\n",
    "advancedtestMeth8 = advancedvectorizerMeth8.transform(verbTest)\n",
    "advpredictionsMeth8 = advancedmodelMeth8.predict(advancedtestMeth8)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"laggedByThree\"][1392:1988], advpredictionsMeth8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 9 - Kaggle, 0 Lag, Verb + Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nounAndVerb\"] = df[\"noun\"].map(str) + df[\"verb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "nounAndVerbTraining = []\n",
    "nounAndVerbTest = []\n",
    "for row in range(0,1391):  \n",
    "    nounAndVerbTraining.append((df[\"nounAndVerb\"][row].lower()))\n",
    "\n",
    "for row in range(1392,1988):\n",
    "    nounAndVerbTest.append((df[\"nounAndVerb\"][row].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5302013422818792\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth9 = CountVectorizer(ngram_range=(4,4))\n",
    "advancedtrainMeth9 = advancedvectorizerMeth9.fit_transform(nounAndVerbTraining)\n",
    "\n",
    "advancedmodelMeth9 = LogisticRegression()\n",
    "advancedmodelMeth9 = advancedmodelMeth9.fit(advancedtrainMeth9, df[\"Label\"][0:1391])\n",
    "\n",
    "advancedtestMeth9 = advancedvectorizerMeth9.transform(nounAndVerbTest)\n",
    "advpredictionsMeth9 = advancedmodelMeth9.predict(advancedtestMeth9)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"Label\"][1392:1988], advpredictionsMeth9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 10 - Kaggle, 1 Lag, Verb + Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5302013422818792\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth10 = CountVectorizer(ngram_range=(4,4))\n",
    "advancedtrainMeth10 = advancedvectorizerMeth10.fit_transform(nounAndVerbTraining)\n",
    "\n",
    "advancedmodelMeth10 = LogisticRegression()\n",
    "advancedmodelMeth10 = advancedmodelMeth10.fit(advancedtrainMeth10, df[\"laggedByOne\"][0:1391])\n",
    "\n",
    "advancedtestMeth10 = advancedvectorizerMeth10.transform(nounAndVerbTest)\n",
    "advpredictionsMeth10 = advancedmodelMeth10.predict(advancedtestMeth10)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"laggedByOne\"][1392:1988], advpredictionsMeth10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 11 - Kaggle, 2 Lag, Verb + Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5335570469798657\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizerMeth11 = CountVectorizer(ngram_range=(4,4))\n",
    "advancedtrainMeth11 = advancedvectorizerMeth11.fit_transform(nounAndVerbTraining)\n",
    "\n",
    "advancedmodelMeth11 = LogisticRegression()\n",
    "advancedmodelMeth11 = advancedmodelMeth11.fit(advancedtrainMeth11, df[\"laggedByTwo\"][0:1391])\n",
    "\n",
    "advancedtestMeth11 = advancedvectorizerMeth11.transform(nounAndVerbTest)\n",
    "advpredictionsMeth11 = advancedmodelMeth11.predict(advancedtestMeth11)\n",
    "\n",
    "print (metrics.accuracy_score(df[\"laggedByTwo\"][1392:1988], advpredictionsMeth11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 12 - Kaggle Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggleTraining = []\n",
    "kaggleTest = []\n",
    "for row in range(0,1391):  \n",
    "    kaggleTraining.append((df[\"combined\"][row].lower()))\n",
    "\n",
    "for row in range(1392,1988):\n",
    "    kaggleTest.append((df[\"combined\"][row].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedvectorizer12 = CountVectorizer(ngram_range=(2,2))\n",
    "advancedtrain12 = advancedvectorizer12.fit_transform(kaggleTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedmodel12 = LogisticRegression()\n",
    "advancedmodel12 = advancedmodel12.fit(advancedtrain12, df[\"Label\"][0:1391])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedtest12 = advancedvectorizer12.transform(kaggleTest)\n",
    "advpredictions12 = advancedmodel12.predict(advancedtest12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5671140939597316\n"
     ]
    }
   ],
   "source": [
    "print (metrics.accuracy_score(df[\"Label\"][1392:1988], advpredictions12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280178</th>\n",
       "      <td>0.257959</td>\n",
       "      <td>the first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139843</th>\n",
       "      <td>0.250185</td>\n",
       "      <td>in china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21741</th>\n",
       "      <td>0.243038</td>\n",
       "      <td>and other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241488</th>\n",
       "      <td>0.232606</td>\n",
       "      <td>right to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121721</th>\n",
       "      <td>0.223348</td>\n",
       "      <td>government has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278255</th>\n",
       "      <td>0.209556</td>\n",
       "      <td>that they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12207</th>\n",
       "      <td>0.208610</td>\n",
       "      <td>after the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128741</th>\n",
       "      <td>0.208278</td>\n",
       "      <td>have to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286150</th>\n",
       "      <td>0.207743</td>\n",
       "      <td>this is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169132</th>\n",
       "      <td>0.204027</td>\n",
       "      <td>likely to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient           Words\n",
       "280178     0.257959       the first\n",
       "139843     0.250185        in china\n",
       "21741      0.243038       and other\n",
       "241488     0.232606        right to\n",
       "121721     0.223348  government has\n",
       "278255     0.209556       that they\n",
       "12207      0.208610       after the\n",
       "128741     0.208278         have to\n",
       "286150     0.207743         this is\n",
       "169132     0.204027       likely to"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = advancedvectorizer12.get_feature_names()\n",
    "advcoeffs = advancedmodel12.coef_.tolist()[0]\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n",
    "advcoeffdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284978</th>\n",
       "      <td>-0.188269</td>\n",
       "      <td>there is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>-0.188353</td>\n",
       "      <td>accused of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253541</th>\n",
       "      <td>-0.194755</td>\n",
       "      <td>sexual abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137652</th>\n",
       "      <td>-0.196025</td>\n",
       "      <td>if he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195264</th>\n",
       "      <td>-0.197356</td>\n",
       "      <td>nuclear weapons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279526</th>\n",
       "      <td>-0.218109</td>\n",
       "      <td>the country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43204</th>\n",
       "      <td>-0.222907</td>\n",
       "      <td>bin laden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302009</th>\n",
       "      <td>-0.224339</td>\n",
       "      <td>up in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318301</th>\n",
       "      <td>-0.225215</td>\n",
       "      <td>with iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290249</th>\n",
       "      <td>-0.232685</td>\n",
       "      <td>to kill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient            Words\n",
       "284978    -0.188269         there is\n",
       "8408      -0.188353       accused of\n",
       "253541    -0.194755     sexual abuse\n",
       "137652    -0.196025            if he\n",
       "195264    -0.197356  nuclear weapons\n",
       "279526    -0.218109      the country\n",
       "43204     -0.222907        bin laden\n",
       "302009    -0.224339            up in\n",
       "318301    -0.225215        with iran\n",
       "290249    -0.232685          to kill"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 13 - Naive Bayes, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictFunc(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    bow_transformer = CountVectorizer(analyzer=text_process).fit(X_train)\n",
    "    messages_bow = bow_transformer.transform(X_train)\n",
    "    tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "    messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "    \n",
    "    stock_model = MultinomialNB().fit(messages_tfidf, y_train)\n",
    "    \n",
    "    messages_bow_xtest = bow_transformer.transform(X_test)\n",
    "    messages_tfidf_xtest = tfidf_transformer.transform(messages_bow_xtest)\n",
    "    \n",
    "    predictions = stock_model.predict(messages_tfidf_xtest)\n",
    "    print (metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"noun\"], df[\"Label\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4919678714859438\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 14 - Naive Bayes, 1 lag, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainNoun1Lag, X_testNoun1Lag, y_trainNoun1Lag, y_testNoun1Lag = train_test_split(df[\"noun\"], df[\"laggedByOne\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5522088353413654\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainNoun1Lag, X_testNoun1Lag, y_trainNoun1Lag, y_testNoun1Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 15 - Naive Bayes, 2 lag, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainNoun2Lag, X_testNoun2Lag, y_trainNoun2Lag, y_testNoun2Lag = train_test_split(df[\"noun\"], df[\"laggedByTwo\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536144578313253\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainNoun2Lag, X_testNoun2Lag, y_trainNoun2Lag, y_testNoun2Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 16 - Naive Bayes, 3 lag, Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainNoun3Lag, X_testNoun3Lag, y_trainNoun3Lag, y_testNoun3Lag = train_test_split(df[\"noun\"], df[\"laggedByThree\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5220883534136547\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainNoun3Lag, X_testNoun3Lag, y_trainNoun3Lag, y_testNoun3Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 17 - Naive Bayes, 0 lag, Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainVerb0Lag, X_testVerb0Lag, y_trainVerb0Lag, y_testVerb0Lag = train_test_split(df[\"verb\"], df[\"Label\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4879518072289157\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainVerb0Lag, X_testVerb0Lag, y_trainVerb0Lag, y_testVerb0Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 18 - Naive Bayes, 1 lag, Verb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainVerb1Lag, X_testVerb1Lag, y_trainVerb1Lag, y_testVerb1Lag = train_test_split(df[\"verb\"], df[\"laggedByOne\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5522088353413654\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainVerb1Lag, X_testVerb1Lag, y_trainVerb1Lag, y_testVerb1Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 19 - Naive Bayes, 2 lag, Verb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainVerb2Lag, X_testVerb2Lag, y_trainVerb2Lag, y_testVerb2Lag = train_test_split(df[\"verb\"], df[\"laggedByTwo\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5481927710843374\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainVerb2Lag, X_testVerb2Lag, y_trainVerb2Lag, y_testVerb2Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 20 - Naive Bayes, 0 lag, Verb+Noun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainNounAndVerb0Lag, X_testNounAndVerb0Lag, y_trainNounAndVerb0Lag, y_testNounAndVerb0Lag = train_test_split(df[\"nounAndVerb\"], df[\"Label\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4919678714859438\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainNounAndVerb0Lag, X_testNounAndVerb0Lag, y_trainNounAndVerb0Lag, y_testNounAndVerb0Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 22 - Naive Bayes, 1 lag, Verb+Noun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainNounAndVerb1Lag, X_testNounAndVerb1Lag, y_trainNounAndVerb1Lag, y_testNounAndVerb1Lag = train_test_split(df[\"nounAndVerb\"], df[\"laggedByOne\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542168674698795\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainNounAndVerb1Lag, X_testNounAndVerb1Lag, y_trainNounAndVerb1Lag, y_testNounAndVerb1Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 23 - Naive Bayes, 1 lag, All\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainAll1Lag, X_testAll1Lag, y_trainAll1Lag, y_testAll1Lag = train_test_split(df[\"combined\"], df[\"laggedByOne\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5522088353413654\n"
     ]
    }
   ],
   "source": [
    "predictFunc(X_trainAll1Lag, X_testAll1Lag, y_trainAll1Lag, y_testAll1Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 24 - h20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/h20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>7 days 2 hours 41 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.18.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 13 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_AK_lom12y</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.926 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         7 days 2 hours 41 mins\n",
       "H2O cluster timezone:       America/Chicago\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.18.0.2\n",
       "H2O cluster version age:    1 month and 13 days\n",
       "H2O cluster name:           H2O_from_python_AK_lom12y\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.926 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.4 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%\n"
     ]
    }
   ],
   "source": [
    "dfh2o = h2o.import_file(\"./data/h20.csv\",header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1989, 3)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfh2o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Label  </th><th>noun                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </th><th>verb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DOWN   </td><td>Georgia, impeached._Russia, South, Ossetia, South, Ossetia, U.N., nothing_150, South, Ossetia, Georgia, Georgia, South, Ossetia, Russia, SO, Salim, Haman, S., Osettain, U.S., Prep, Georgia, War, Green, Light, Israel, Attack, Iran, U.S., Class, Action, Lawsuit, Behalf, American, Public, FBI_So, Russia, Georgia, NYT, Olympics, journalism._China, Bush, World, War, III, Invades, South, Ossetia, Russia, NATO, Georgia, Islamist, Backlash_Condoleezza, Rice, US, Iran, Defense, Minister, Ehud, Barak, Israel, European, Union, Iran, Iraq, Georgia, South, Pentagon, Iran, Idea, US, News, World, Report_Caucasus, Georgia, South, Mental, Illnesses, Olympics_No, Help, Mexico, Kidnapping, Surge</td><td>move, brink, be, roll, fighting, are, moving, has, been, destroyed, raped, says, is, was, raped, do, have, entered, shoots, invades, warned, would, intervene, are, has, been, sentenced, will, be, kept, feel, retreat, leaving, killed, VIDEO]_Did, Gives, Says, has, are, is, opening, tells, stay, affairs_Did, gets, involved, will, absorb, unleash, Faces, would, act, prevent, is, prepared, is, has, approved, will, withdraw, help, fight, Ossetia_Why, Thinks, Attacking, is, invades, do, like, Suffering, Banned</td></tr>\n",
       "<tr><td>UP     </td><td>America, Nato, Iraq?_Bush, Russia, _, Russians, Gori, Russia, Mossad, New, Zealand, Passports, Georgia_An, S.Ossetia, U.S., World, War, IV, High, Definition!_Georgia, Russia, Georgia, U.S., goal_Abhinav, Bindra, Olympic, Gold, Medal, India, _, U.S., Arctic, Jerusalem, Ara_The, French, Team, Phelps, Relay, Team_Israel, US, Georgian, Montreal, Canada, Saturday._China, US, manufacturer_War, South, Ossetia, PICS]_Israeli, Physicians, Group, Condemns, State, Torture, Russia, United, States, Peak, Georgia, Russia, Russia                                                                                                                                                                     </td><td>wo, help, wo, help, did, help, puts, re, fending, abandoned, were, doing, angered, living, blames, presses, says, is, wins, define, threaten, quit, is, Stunned, believe, are, are, going, murdered, overtake, has, beaten, is, is, s, come                                                                                                                                                                                                                                                                                  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfh2o.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:1989\n",
      "Cols:3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Label  </th><th>noun                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th><th>verb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum   </td><td>string                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td><td>string                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       </td></tr>\n",
       "<tr><td>mins   </td><td>       </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr>\n",
       "<tr><td>mean   </td><td>       </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr>\n",
       "<tr><td>maxs   </td><td>       </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr>\n",
       "<tr><td>sigma  </td><td>       </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr>\n",
       "<tr><td>zeros  </td><td>       </td><td>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           </td><td>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr>\n",
       "<tr><td>missing</td><td>0      </td><td>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           </td><td>3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr>\n",
       "<tr><td>0      </td><td>DOWN   </td><td>Georgia, impeached._Russia, South, Ossetia, South, Ossetia, U.N., nothing_150, South, Ossetia, Georgia, Georgia, South, Ossetia, Russia, SO, Salim, Haman, S., Osettain, U.S., Prep, Georgia, War, Green, Light, Israel, Attack, Iran, U.S., Class, Action, Lawsuit, Behalf, American, Public, FBI_So, Russia, Georgia, NYT, Olympics, journalism._China, Bush, World, War, III, Invades, South, Ossetia, Russia, NATO, Georgia, Islamist, Backlash_Condoleezza, Rice, US, Iran, Defense, Minister, Ehud, Barak, Israel, European, Union, Iran, Iraq, Georgia, South, Pentagon, Iran, Idea, US, News, World, Report_Caucasus, Georgia, South, Mental, Illnesses, Olympics_No, Help, Mexico, Kidnapping, Surge                                               </td><td>move, brink, be, roll, fighting, are, moving, has, been, destroyed, raped, says, is, was, raped, do, have, entered, shoots, invades, warned, would, intervene, are, has, been, sentenced, will, be, kept, feel, retreat, leaving, killed, VIDEO]_Did, Gives, Says, has, are, is, opening, tells, stay, affairs_Did, gets, involved, will, absorb, unleash, Faces, would, act, prevent, is, prepared, is, has, approved, will, withdraw, help, fight, Ossetia_Why, Thinks, Attacking, is, invades, do, like, Suffering, Banned</td></tr>\n",
       "<tr><td>1      </td><td>UP     </td><td>America, Nato, Iraq?_Bush, Russia, _, Russians, Gori, Russia, Mossad, New, Zealand, Passports, Georgia_An, S.Ossetia, U.S., World, War, IV, High, Definition!_Georgia, Russia, Georgia, U.S., goal_Abhinav, Bindra, Olympic, Gold, Medal, India, _, U.S., Arctic, Jerusalem, Ara_The, French, Team, Phelps, Relay, Team_Israel, US, Georgian, Montreal, Canada, Saturday._China, US, manufacturer_War, South, Ossetia, PICS]_Israeli, Physicians, Group, Condemns, State, Torture, Russia, United, States, Peak, Georgia, Russia, Russia                                                                                                                                                                                                                    </td><td>wo, help, wo, help, did, help, puts, re, fending, abandoned, were, doing, angered, living, blames, presses, says, is, wins, define, threaten, quit, is, Stunned, believe, are, are, going, murdered, overtake, has, beaten, is, is, s, come                                                                                                                                                                                                                                                                                  </td></tr>\n",
       "<tr><td>2      </td><td>DOWN   </td><td>Georgia, Iraq, Islamic, Georgia, Putin, Outmaneuvers, Microsoft, Intel, Russo, Georgian, War, Balance, Power, Whole, Georgia, Russia, War, Georgia, Russia, Did_The, US, South, Ossetia, US, Monday_U.S., Beats, War, Drum, Iran, Dollar_Gorbachev, South, Tskhinvali, Tskhinvali, Olympics, Games, IOC, Russia._55, Luxor, Tokyo, Bay_The, Top, Party, Cities, World_U.S., Georgia, Georgia, Russias, Georgia, right_Gorbachev, U.S., Caucasus, region_Russia, Georgia, NATO, Cold, War, Two_Remember, Georgia, connection_All, US, Georgia, South, Ossetia, Goddamnit, Bush._Christopher, King, US, NATO, South, Ossetia, America, New, Mexico?_BBC, NEWS, |, Asia, Pacific, |, Extinction                                                                </td><td>Remember, sang, was, ends, had, would, have, is, losing, regards, including, buying, tried, kill, _, m, Trying, Get, Vote, Think, Started, Think, was, surprised, is, trying, sort, happened, said, Dumps, attacked, designed, devastate, ruins, cover, VIDEO]_Beginning, were, opening, violates, could, respond, taking, stacked, did, know, were, was, accuses, making, pursuing, led, based, was, too._War, encouraging, invade, argues, are, have, misjudged, _, climate                                                </td></tr>\n",
       "<tr><td>3      </td><td>DOWN   </td><td>U.S., Israel, Iran, Tskhinvali, South, Ossetia, Israel, Reuters, cameraman_Britain\\, Mexico, Head, Prez, force_China, Operation, Russia, Grill, Navy, President, CNN, Russia, Georgia, justified!_USA, Black, Sea, Georgia, Iran, Georgia, Russia_The, CNN, Effect, Georgia, Schools, Russia, Information, Warfare_Why, Russias, Georgia, Georgia, Russia, US, WWIII?_Georgia, US, Georgia, US, Tbilisi, Quarter, Russians, U.S., US, Pentagon, Nobel, Aleksander, Solzhenitsyn, U.S., NATO, Russia                                                                                                                                                                                                                                                         </td><td>refuses, attack, report_When, ordered, attack, knew, were, doomed, come, did, realize, _, clears, killed, being, is, says, ran, found, paid, quits, dissolves, suspect, has, moved, homes_Bush, announces, Get, will, end, sink, _, provides, command, has, been, relieved, send, help, send, warns, strike, are, heading, keep, running, was, extinct, hits, came, violating, Had, head, blame, says, will, take, accuses, encircling                                                                                       </td></tr>\n",
       "<tr><td>4      </td><td>UP     </td><td>_, War, South, Osetia, Ara, Abrahamian, Russia, South, Ossetia, Pakistan, CIA_Rushdie, Condemns, Random, House, Refusal, Publish, Novel, US, Russians, Tblisi, it_Russia, South, _, Musharraf, impeachment_Moscow, Plans, Georgia_Why, Russias, Georgia, right_Nigeria, Bakassi, Cameroon._The, US, Poland, US, shield_Russia, early_Georgia, Russia, US, |, World, |, Caucasus, South, Ossetia, Georgia, video]_Saudi, Arabia, marriage_Taliban, workers_Russia, Georgia\\, integrity_Darfur, Sudan, Peace, Advocate, Muslims, Christians                                                                                                                                                                                                                   </td><td>admit, should, legalise, made, throws, exaggerated, were, killed, compared, Killed, May, Have, Been, Launched, agree, missle, conquer, can, BET, exaggerating, says, expected, resign, Made, Invade, was, has, handed, have, agreed, is, sabotaging, battered, could, set, is, shot, moves, block, can, forget, accuse, mounting, say, need, convert                                                                                                                                                                         </td></tr>\n",
       "<tr><td>5      </td><td>UP     </td><td>U.S., Poland, Missile, Deal, UK, UN, government._Gorbachev, Georgia, S., Ossetia_China, Olympics, UN, UK, Poland, Bush, Moscow, Georgia_Russia, site_Russia, Georgia, Conflict, Rush, Control, Caspian, Energy, Resources_Business, Week, Georgia, Russia, Caspian, West, Georgia, Seize, US, Weapons, Depot, Russias, Georgia, Americas, Hari, Islam_US, Georgia, permanent_Israel, Reuters, cameraman_Unenforceable, like_Hacker, Kidnaps, Tortures, Informant, Posts, Picture, Tells, Putin                                                                                                                                                                                                                                                              </td><td>missing, s, d, be, looking, Wo, Go, has, been, accused, creating, have, chilling, has, lashed, suggested, might, be, resurfacing, started, were, are, threatens, demands, withdraws, can, inspect, Fueled, gives, did, believe, have, learnt, has, is, believe, have, been, accused, building, retaining, convicted, can, forget, regaining, are, need, stop, being, have, said, will, become, clears, killed, encourage, escalate, looks, Others_Bush, Will, Stand_Georgia, is, say, plan, remove                           </td></tr>\n",
       "<tr><td>6      </td><td>DOWN   </td><td>Musharraf, Country_Tornado, Poland, passengers_Britain, Non, Muslims, Maldives, constitution_Tour, Tskhinvali, fighting_The, Great, Resource, War, Middle, East, Global, War, Terror, US, Iraq_Russia, SS-21, Georgia, US, President, Georgia, Russians_New, Cold, War, _, Georgian, Situation, Quest, Prize, Oil, Power_MI5, Canadians, stuff_The, Neighbor, Vladimir, Putin, Powerless, West_Israel, Russians, saner._NATO, Hour_Georgian, President, Saakashvili, Eats, Tie, TV_No, Chicken, innocent_Mayor, Ugly, Women                                                                                                                                                                                                                                 </td><td>are, serving, being, _, re, are_Pakistan, s, Resign, Leave, throws, captured, have, left, satellite, restricted, undercuts, is, scattered, disguised, _, working, moves, official_a, says, is, resigning, avoid, would, harm, shuts, owned, is, Continues, seeks, _, lets, strut, Takes, are, Left, Arrives, has, given, must, leave, be, grows, Asks, Visit                                                                                                                                                                 </td></tr>\n",
       "<tr><td>7      </td><td>DOWN   </td><td>US, Kabul, China, wasteland_Russia, US, vehicles_Muslims, Denmark, Muslim._Taliban, Forces, Kill, Soldiers, Raid, U.S., years_South, Ossetia, Michael, Phelps, pic]_New, York, Beijing, Tibet, Protest, Nato, Shai, Agassi, Electric, Cars, Road, _, NATO, Georgia_Brazil, Military, War, Game, Discovered, Offshore, Oil_16,000, Facebook_Today, August, UN, Iraq_US, Ken, Haywood, India, Taliban, Afghan, capital_Not, Wind, Forces, Kill, Soldiers, Raid, U.S., Base, Pakistan, America, Blaze                                                                                                                                                                                                                                                          </td><td>arrested, locked, taking, ignoring, is, will, run, lambasted, blaming, killed, _, make, seizes, are, make, convicted, are, have, doubled, Is, take, detained, left, isolated, maintain, Put, freezes, Will, Play, Defend, caught, sharing, is, was, found, send, flees, _, kill, Loves, is, _                                                                                                                                                                                                                                </td></tr>\n",
       "<tr><td>8      </td><td>UP     </td><td>Power, Islam, Human, Rights, Council, United, Nations, Sharia, Law, Islamic, World_We, Gulf, War, Iraq, Obama\\, Kenya, Russia, Old, Europe, Bush, McCain, Georgia, NATO._Abkhazia, Russia, independence_Russia, US, shield_India, Sets, Regional, Wasteland, Jatropha, Biodiesel, Chinese, Women, Labor, Re, Madrid_Taliban, Dead, Plane, Crash, Madrid, Western, Intelligence, India, Ahmedabad, Spanish, Freedom, Speech, Dies, Ignoble, Death, Grote, Markt, PIC]_Russia, Norway, Aims, War, French, Rethink, Afghanistan, Mission_Bush, Musharraf, Ties, Al, Qaeda_Mikhail, Gorbachev, Russia, War_Germans, Wimps, Dialogue, Russia, Only, Choice_1998, Missile, Strikes, Bin, Laden, First, Solar, Radio, Station, Argentina                           </td><td>have, been, sentenced, sought, demonstrate, has, banned, regarding, had, sends, Syria._The, should, be, having, spiked, bring, Sentenced, Applying, Protest, skids, mount, allied, Feared, Was, involved, was, used, send, _, Will, be, Offended, has, informed, plans, cut, Are, Covered, Wanted, urge, _, Is, May, Have, let, forget, pay                                                                                                                                                                                  </td></tr>\n",
       "<tr><td>9      </td><td>UP     </td><td>Guantanamo, Bay, Foreign, Office, Tibetans, Dalai, Lama_U.S., Navy, Ships, Head, Georgia_Hacker, Kim, Jong, Il, Nuclear, President, Caucasus._50, All, Food, Baghdad, GRL, James, Powderly, Tibet, Olympics_Go, Georgia, NATO, Russia, Archduke, Ferdinand_Cafferty, Georgia, War, Russia, vid]_Kazakhstan, BTC, Georgia, Russia, Israel, enemies_Belfast, Police, Confiscate, Boardgame, Terrorist, Age, 138_Russia, US, Moscow, Washingtons, Pakistan, Sixteen, Fraudulent, Fourteen, Hackers, Russias, Gymnasts, Official, Document, Pakistan, factory_The, Abkhazian, Parliament, Russia, independence_Georgia, Bulgaria, Second, Balkan, War, |, |, Fistful, Euros, |, European, Opinion_Terrorist, Pak, India_International, Olympic, Committee, Kexin</td><td>held, wins, force, reveal, may, have, killed, fraud_If, ve, wondered, was, go, was, ordered, Is, must, protest, Produced, Is, Wasted, Gets, amp, covering, let, declare, gets, audition, Started, is, considering, diverting, runs, using, threatens, Dies, condemns, missile, freeze, inept, are, feeling, can, bring, grinding, kills, has, approved, recognise, reveals, launches                                                                                                                                         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfh2o.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"Label\"\n",
    "x = dfh2o.columns\n",
    "x.remove(y)\n",
    "# x.remove(\"laggedByOne\")\n",
    "# x.remove(\"laggedByTwo\")\n",
    "# x.remove(\"laggedByThree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noun', 'verb']"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Label'"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nounAndVerbTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_models = 10, seed = 1)\n",
    "aml.train(x = x, y = y, training_frame = dfh2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_0_AutoML_20180401_195533_model_4            </td><td style=\"text-align: right;\">0.519296</td><td style=\"text-align: right;\"> 0.692541</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180401_195533_model_3            </td><td style=\"text-align: right;\">0.517824</td><td style=\"text-align: right;\"> 0.721868</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180401_195533_model_2            </td><td style=\"text-align: right;\">0.51151 </td><td style=\"text-align: right;\"> 0.715895</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180401_195533_model_1            </td><td style=\"text-align: right;\">0.50992 </td><td style=\"text-align: right;\"> 0.714119</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180401_195533_model_0            </td><td style=\"text-align: right;\">0.50345 </td><td style=\"text-align: right;\"> 0.715074</td></tr>\n",
       "<tr><td>DeepLearning_0_AutoML_20180401_195533                </td><td style=\"text-align: right;\">0.495189</td><td style=\"text-align: right;\"> 0.714597</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_0_AutoML_20180401_195533   </td><td style=\"text-align: right;\">0.49355 </td><td style=\"text-align: right;\"> 0.689716</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_0_AutoML_20180401_195533</td><td style=\"text-align: right;\">0.49355 </td><td style=\"text-align: right;\"> 0.689716</td></tr>\n",
       "<tr><td>DRF_0_AutoML_20180401_195533                         </td><td style=\"text-align: right;\">0.486147</td><td style=\"text-align: right;\"> 2.21771 </td></tr>\n",
       "<tr><td>XRT_0_AutoML_20180401_195533                         </td><td style=\"text-align: right;\">0.48532 </td><td style=\"text-align: right;\"> 1.60749 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 25 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5302013422818792"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = text_clf.fit(kaggleTraining, df[\"Label\"][0:1391])\n",
    "predicted = text_clf.predict(kaggleTest)\n",
    "np.mean(predicted == df[\"Label\"][1392:1988])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AK\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "_ = text_clf_svm.fit(kaggleTraining, df[\"Nasdaq\"][0:1391])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5318791946308725"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svm = text_clf_svm.predict(kaggleTest)\n",
    "np.mean(predicted_svm == df[\"Nasdaq\"][1392:1988])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 25 - Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('mnb', MultinomialNB(fit_prior=False)),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5302013422818792"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_mnb_stemmed = text_mnb_stemmed.fit(kaggleTraining,df[\"Label\"][0:1391])\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(kaggleTest)\n",
    "np.mean(predicted_mnb_stemmed == df[\"Label\"][1392:1988])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
